from typing import Dict, Any, List
from langchain_groq import ChatGroq
from core.retriever import RAGRetriever

class RAGPipeline:
    """Encapsulates the full RAG pipeline from query to answer."""
    
    def __init__(self, retriever: RAGRetriever, llm: ChatGroq):
        self.retriever = retriever
        self.llm = llm

    def _format_context(self, documents: List[Dict[str, Any]]) -> str:
        """Formats the retrieved documents into a single context string."""
        return "\n\n---\n\n".join([doc['content'] for doc in documents])

    def _create_prompt(self, query: str, context: str) -> str:
        """Creates the final prompt for the LLM."""
        return f"""You are an expert Q&A assistant. Your task is to use the following context to answer the question.

        Instructions:
        1. Do not make assumptions.
        2. Elaborate your answers with details from the context.
        3. Provide concise and accurate answers.
        4. Cite sources when applicable.
        5. If multiple sources provide the same information, consolidate them into a single answer.
        6. Always refer to the context provided.
        7. If the context does not contain enough information to answer the query, reply with: "I cannot answer this query based on the provided context."
        8. Retrieve if any images and/or tables are mentioned in the context to support your answer.
        9. Produce answers in markdown format for better readability.
        10. Provide approximate or near answer if exact answer is not found in the context.

        Here is the context and the question you need to answer:
        ---
        CONTEXT:
        {context}
        ---
        QUESTION:
        {query}
        ---
        ANSWER:
        """

    def ask(self, query: str, top_k: int = 3, min_score: float = 0.2) -> Dict[str, Any]:
        """Executes the RAG pipeline."""
        # 1. Retrieve documents
        retrieved_docs = self.retriever.retrieve(
            query=query, 
            top_k=top_k, 
            score_threshold=min_score
        )

        if not retrieved_docs:
            return {
                'answer': "No relevant context was found to answer your query.",
                'sources': [],
                'confidence': 0.0
            }

        # 2. Format context and create prompt
        context = self._format_context(retrieved_docs)
        prompt = self._create_prompt(query, context)
        
        # 3. Generate answer
        print("ðŸ’¬ Generating answer with LLM...")
        response = self.llm.invoke(prompt)
        
        # 4. Compile results
        sources = [{
            'source': doc['metadata'].get('source', 'unknown'),
            'page': doc['metadata'].get('page', 'N/A'),
            'score': doc['score']
        } for doc in retrieved_docs]
        
        confidence = max(doc['score'] for doc in retrieved_docs)
        
        result = {
            'answer': response.content,
            'sources': sources,
            'confidence': confidence
        }
        
        return result